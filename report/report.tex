\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage[tmargin=2.0cm, lmargin=4cm, rmargin=4cm]{geometry}
\usepackage{listings}             % Include the listings-package
\usepackage{textcomp}
\usepackage{listings}
%\usepackage{minted}      % (requires -shell-escape)
\usepackage{xcolor}
\usepackage{filecontents}
\usepackage{array}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{float}

\newcolumntype{L}{>{\centering\arraybackslash}m{3cm}}

\lstset{language=Matlab,%
	morekeywords={matlab2tikz},
	keywordstyle=\color{blue},
	morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
	identifierstyle=\color{black},
	stringstyle=\color{blue},
	commentstyle=\color{orange},
	showstringspaces=false,%without this there will be a symbol in the places where there is a space
	numbers=left,%
	numberstyle={\tiny \color{black}},% size of the numbers
	numbersep=9pt, % this defines how far the numbers are from the text
	emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
	%emph=[2]{word1,word2}, emphstyle=[2]{style},
}

% global settings
\lstset
{
  captionpos = below,
  frame      = single,
  breaklines          = true,
  %postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}},
  columns    = fullflexible,
  basicstyle = \ttfamily,
}


%\titlespacing*{\chapter}{0pt}{-19pt}{18pt}

\newcommand{\mychapter}[2]{
    \setcounter{chapter}{#1}
    \setcounter{section}{0}
    \chapter*{#2}
    \addcontentsline{toc}{chapter}{#2}
}
% \topskip 50pt
%\titlespacing*{\mychapter}{0cm}{-50pt}{0pt}[0pt]

\begin{document}

\begin{titlepage}
	\newpage
	\thispagestyle{empty}
	\frenchspacing
	\hspace{-0.2cm}
	\includegraphics[height=3.4cm]{sedes}
	\hspace{0.2cm}
	\rule{0.5pt}{3.4cm}
	\hspace{0.2cm}
	\begin{minipage}[b]{8cm}
		\Large{Katholieke\newline Universiteit\newline Leuven}\smallskip\newline
		\large{}\smallskip\newline
		\textbf{Department of\newline Computer Science}\smallskip
	\end{minipage}
	\hspace{\stretch{1}}
	\vspace*{3.2cm}\vfill
	\begin{center}
		\begin{minipage}[t]{\textwidth}
			\begin{center}
				\LARGE{\rm{\textbf{\uppercase{Project: TSP}}}}\\
				\Large{\rm{Genetic Algorithms and Evolutionary Computing (B-KUL-H02D1A) }}\\
				\vspace{0.5cm}

			    \large{\textsc{Verbois-Halilovic}}%

			\end{center}
		\end{minipage}
	\end{center}
	\vfill
	\hfill\makebox[8.5cm][l]{%
		\vbox to 7cm{\vfill\noindent
				{\rm \textbf{Sten Verbois (r0680459)}}\\
				{\rm \textbf{Armin Halilovic (r0679689)}}\\[2mm]
				{\rm Academic year 2017-2018}

		}
	}
\end{titlepage}

\newpage
\tableofcontents
\newpage

\mychapter{0}{Introduction}
In this report we discuss our solutions and results for the given tasks. We ran experiments for each task to evaluate our solutions. Unless stated otherwise, the experiments were executed with a certain set of parameters and functions. This was done so that we would have a consistent basis to compare results on. The parameters were also chosen in order to leave enough room for improvement so that the effects of different methods can be compared, while at the same time reducing variation of experiments that are too short or do too little work. The default parameters and functions are as follows:
\begin{itemize}
	\item \texttt{number of individuals} = 100
	\item \texttt{maximum number of generations} = 250
	\item \texttt{probability of mutation} = 0.05
	\item \texttt{probability of crossover} = 0.95
	\item \texttt{percentage of elite population} = 0.05
	\item \texttt{subpopulations} = 1
	\item \texttt{loop detection} = off
	\item \texttt{parent selection function} = sus
	\item \texttt{crossover function} = cross\_alternating\_edges
	\item \texttt{mutation function} = mut\_inversion
	\item \texttt{custom stopping criterion} = on
	\item \texttt{custom survivor selection function} = off
\end{itemize}
The results shown in all tables except for the benchmarks of task 6 are the average results of 10 runs. Every experiment is ran 10 times so that the effects of local optima would be reduced.

The appendix includes extra tables that contain results of experiments and our code that is relevant to the tasks.

\mychapter{1}{Tasks}

\section{Task 2: Initial experiments}
The impact of the following parameters on the results of the existing genetic algorithm was tested by varying them while keeping the rest of the parameters at their default values:
\begin{itemize}
	\item number of individuals (NIND)
	\item maximum number of generations (MAXGEN)
	\item percentage of the elite population (ELITIST)
	\item probability of crossover (PR\_CROSS)
	\item probability of mutation (PR\_MUT)
	\item local loop removal (LOCALLOOP)
\end{itemize}
The parameter values were chosen so that evenly spread out values from low to high could be tested. The experiments for this task were executed on a subset of the given datasets to keep the tables readable. The datasets range from ones with a small amount of cities to ones with a large amount of cities. The tables for the results of the experiments can be found in appendix~\ref{app:task2}. The custom stopping criterion was not used during these experiments, as it is discussed in section~\ref{sec:stopping_criterion}.

\subsection{Individuals}
The mininum path lengths clearly decrease as the number of individuals increases. This is to be expected, as a larger amount of individuals causes a larger amount of mutations and crossover which can positively impact path lengths. Analogously, the maximum path lengths slightly increase as the number of individuals increases. Because of this effect, the mean path lengths remain relatively constant after 100 individuals. Improvements to the minima are higher when increasing a lower number of individuals than when increasing an already high number of individuals.

\subsection{Generations}
Increasing the number of generations shows effects similar to the ones of increasing the number of individuals. However, these results show that increasing an already high number of generations improves the minima a relatively equal amount to increasing a lower number of generations. Also, the means and maxima are lower for high numbers of generations than they are for high numbers of individuals. This can be explained by the survivor selection having more opportunities to select better paths when the amount of generations is higher.
Note that the algorithm stops at around 180 generations for dataset "rondrit016.tsp". This is due to the stopping criterion of the existing algorithm being triggered.

\subsection{Elitism}
Judging from the jump in results between 0 elitism and all other values for elitism, it is better to have elitism than to not have it at all. The results improve as the elitism grows from low to medium values, but then worsen again as it goes to high values. A percentage of around 30 to 50 performs best. The results become worse again at high values because crossover and mutation happens a lot less at those values.

\subsection{Crossover}
The crossover results show that the default very high probability performs poorer than all other options for crossover. Furthermore, it is better to have a probability of crossover greater than zero. Similarly to elitism, the results are best at medium probabilities around 30 to 50 percent. When the probability of crossover is high, many more children are created, which creates a lower probability for good parents to be preserved in later generations.

\subsection{Mutation}
The results don't change much for different values of mutation. Judging from the minima, means, and maxima, the best performance again lies around probabilities of 30 to 50 percent.

\subsection{Loop removal}
See section~\ref{sec:local}

\subsection{Mix}
After some parameter tuning with the above information in mind, we have come up with a configuration of parameters that performs very well. The results can be seen in table~\ref{tab:existing_tuning}. The parameters were: \texttt{number of individuals} = 450, \texttt{maximum number of generations} = 400, \texttt{probability of mutation} = 0.4, \texttt{probability of crossover} = 0.5, \texttt{percentage of elite population} = 0.45, \texttt{subpopulations} = 1, \texttt{loop detection} = on, \texttt{selection function} = sus, \texttt{crossover function} = cross\_alternating\_edges, \texttt{mutation function} = mut\_inversion, \texttt{custom stopping criterion} = off, \texttt{custom survivor selection function} = off.
\input{task2_tuning}



\section{Task 3: Stopping criterion}
\label{sec:stopping_criterion}
To implement a new stopping criterion, we looked at the commonly used termination conditions outlined by the textbook. There we see the following suggestions:
\begin{enumerate}
	\item Maximally allowed CPU time elapses.
	\item Total number of fitness evaluations reaches limit.
	\item Fitness improvement remains under threshold for a given period of time.
	\item Population diversity drops under threshold.
\end{enumerate}
The first and second criteria are useful, either to guarantee the evaluations do not go on forever, or when there is some kind of constraint on system resource usage. In the project template, we already have the guarantee of eventual termination because of the limit on the number of generations, and we do not have to account for system resource constraints in this context.

The fourth criterion is also already present in the template. The default value is so strict (95\% equal individuals), it practically is never reached.

We decided to implement the third criterion. With this condition, termination occurs when the fitness of the best individual does not improve above a threshold for a given period of time. This period of time is expressed in terms of a certain number of generations. We chose to define this number of generations to be 10\% of the specified maximum number of generations.

The results of our experiments with this new termination condition are displayed in table~\ref{tab:customstop}. We clearly see that it does succeed in avoiding computation of useless generations where the fitness does not improve for a long time. As expected, the achieved score is often slightly worse in comparison to the default stopping criterion. This is because of the fact that improvements may still happen at a much later point in time. With a more strict stopping criterion, we make a trade-off between avoiding almost useless calculations and the chance for slightly better scores.
\input{task3_results}

\newpage
\section{Task 4: Other representation}
The given project template uses adjacency representation by default for TSP paths. We have chosen to use path representation as the alternative one. Conversion between the two representations was already possible thanks to the \texttt{adj2path} and \texttt{path2adj} functions in the template. To do crossover with path representation, we implemented the Order Crossover method (function \texttt{cross\_order}) as described in the textbook. Simple Inversion Mutation, which is a mutation operator for path representation, was already provided in the template (\texttt{mut\_inversion}). We have decided to extend this and have added a function for Inversion Mutation (\texttt{mut\_inversion2}). Our custom stopping criterion was not used during these experiments in order to allow for the different crossover and mutation operators to have a stronger impact.

Table~\ref{tab:path_repr_crossover} contains the results of experiments with different crossover operators. The function \texttt{cross\_alternating\_edges} implements Alternating Edge Crossover and is provided in the template. Order Crossover performs significantly better than Alternating Edge Crossover; all of the path lengths with Order Crossover are lower for every dataset. This can be attributed to Order Crossover retaining longer sequences of genetic material of parents than Alternating Edge Crossover. Also, this results in the path lengths converging to a value earlier, which is why the numbers of generations are lower. 
\input{task4_crossover}

Table~\ref{tab:path_repr_mutation} contains the results of experiments with different mutation functions. The function \texttt{mut\_inversion} implements Simple Inversion Mutation and is provided in the template. While both functions perform roughly the same, the one provided in the template performs slightly better when looking at the minima, means, and maxima. This is likely due to Inversion Mutation changing genetic material more than Simple Inversion Mutation; moving the randomly chosen subpath to a different position in the path after reversing it is more likely to have a negative effect when the path is near a (local) optimum. 
\input{task4_mutation}


Table~\ref{tab:path_repr_tuning} shows results after some parameter tuning with the \texttt{cross\_order} and \texttt{mut\_inversion} operators. The parameters used were: \texttt{number of individuals} = 1000, \texttt{maximum number of generations} = 1000, \texttt{probability of mutation} = 0.30, \texttt{probability of crossover} = 0.50, \texttt{percentage of elite population} = 0, \texttt{subpopulations} = 1, \texttt{loop detection} = on, \texttt{selection function} = sel\_tournament, \texttt{crossover function} = cross\_order, \texttt{mutation function} = mut\_inversion, \texttt{custom stopping criterion} = on, \texttt{custom survivor selection function} = on (round robin tournament).
\input{task4_tuning}

\newpage
\section{Task 5: Local optimisation}
\label{sec:local}
For this task, we are testing the local optimization already present in the template. This optimization takes a path and tries to remove local loops with a path length of up to 3.

The results of our experiments with local optimisation disabled and enabled are displayed in table~\ref{tab:localopt}. With default values for other parameters, this results in major improvements to both path lenghts and number of generations needed. This is the case for every single dataset.
\input{task5_results}


\section{Task 7: Optional tasks}
\subsection{7a: Parent selection}
Additional parent selection methods we implemented are Fitness Proportional Selection (\texttt{sel\_fit\_prop}) and Tournament Selection (\texttt{sel\_tournament}). Both of them use the same parameters as the existing implementation of Stochastic Universal Sampling so we could easily swap them in.

The results of our experiments with all three parent selection methods are displayed in tables~\ref{tab:selparentsus}, \ref{tab:selparenttournament}, and \ref{tab:selparentfitprop}. For Tournament Selection, the tournament size parameter $k$ was set to 5. We see that it achieves much better path lengths than SUS, especially when dealing with a high number of cities. The number of generations needed is quite a bit higher so it seems that SUS gets stuck in local optima while tournament selection is able to select better parents for future generations. This is not the case for Fitness Proportional Selection. This parent selection method seems to match the Stochastic Universal Sampling in terms of path lengths and number of generations needed. This is probably because the methods are very similar to each other.

\begin{table}[H]
	\centering
	\makebox[\textwidth]{
		\begin{tabular}{l rrrr}
			\toprule
			& \multicolumn{4}{c}{Stochastic Universal Sampling} \\
			\cmidrule{2-5}
			Dataset & \# Generations & Min & Mean & Max \\
			\midrule
rondrit016.tsp & 76.5 & 3.5071 & 4.7287 & 6.2973 \\
rondrit018.tsp & 112.0 & 3.2458 & 4.9674 & 6.9154 \\
rondrit023.tsp & 89.8 & 4.3998 & 6.9255 & 9.6426 \\
rondrit025.tsp & 81.6 & 5.8037 & 9.2203 & 12.4602 \\
rondrit048.tsp & 115.7 & 10.5298 & 15.0273 & 18.9340\\
rondrit050.tsp & 74.1 & 15.5617 & 20.4526 & 24.5841\\
rondrit051.tsp & 101.3 & 14.7763 & 19.2497 & 23.2194\\
rondrit067.tsp & 98.2 & 14.7791 & 19.1254 & 22.6560\\
rondrit070.tsp & 117.4 & 22.9912 & 29.3627 & 34.8783\\
rondrit100.tsp & 91.4 & 37.0343 & 44.2892 & 51.0612\\
rondrit127.tsp & 120.9 & 22.9939 & 26.6807 & 30.0838\\
			\bottomrule
		\end{tabular}
	}
	\caption{Results when using Stochastic Universal Sampling as parent selection method.}
	\label{tab:selparentsus}
\end{table}

\begin{table}[H]
	\centering
	\makebox[\textwidth]{
		\begin{tabular}{l rrrr}
			\toprule
			& \multicolumn{4}{c}{Tournament Selection} \\
			\cmidrule{2-5}
			Dataset & \# Generations & Min & Mean & Max \\
			\midrule
rondrit016.tsp & 47.6 & 3.4307 & 3.4489 & 4.1168\\
rondrit018.tsp & 69.8 & 3.0751 & 3.1000 & 3.9496\\
rondrit023.tsp & 97.2 & 3.4223 & 3.4448 & 4.3663\\
rondrit025.tsp & 107.1 & 4.2080 & 4.2289 & 5.2293\\
rondrit048.tsp & 220.2 & 5.2384 & 5.3288 & 6.7016\\
rondrit050.tsp & 228.5 & 7.4060 & 7.4469 & 8.7495\\
rondrit051.tsp & 223.4 & 7.7256 & 7.8091 & 9.0010\\
rondrit067.tsp & 246.7 & 6.5806 & 6.6540 & 7.7929\\
rondrit070.tsp & 250.0 & 10.4302 & 11.1550 & 14.0566\\
rondrit100.tsp & 241.3 & 18.2543 & 19.2141 & 22.2169\\
rondrit127.tsp & 250.0 & 13.2633 & 13.8539 & 15.8462\\
			\bottomrule
		\end{tabular}
	}
	\caption{Results when using Tournament Selection as parent selection method.}
	\label{tab:selparenttournament}
\end{table}

\begin{table}[H]
	\centering
	\makebox[\textwidth]{
		\begin{tabular}{l rrrr}
			\toprule
			& \multicolumn{4}{c}{Fitness Proportional Selection} \\
			\cmidrule{2-5}
			Dataset & \# Generations & Min & Mean & Max \\
			\midrule
rondrit016.tsp & 87.6 & 3.5253 & 4.7702 & 6.31735983363770 \\
rondrit018.tsp & 106.5 & 3.1629 & 5.0059 & 6.88030465197992 \\
rondrit023.tsp & 72.1 & 4.6849 & 7.0675 & 9.61113827405700 \\
rondrit025.tsp & 115.5 & 5.7095 & 9.0493 & 12.57024535746879 \\
rondrit048.tsp & 93.0 & 10.6731 & 15.1775 & 19.06378066242915 \\
rondrit050.tsp & 84.1 & 15.6907 & 20.4983 & 24.46309616398185 \\
rondrit051.tsp & 114.1 & 14.6637 & 19.0878 & 22.88529001223297 \\
rondrit067.tsp & 101.7 & 14.8841 & 19.0997 & 22.56887763300833 \\
rondrit070.tsp & 101.4 & 23.2645 & 29.7146 & 35.05263230223609 \\
rondrit100.tsp & 95.0 & 37.2210 & 43.9292 & 50.80513760208527 \\
rondrit127.tsp & 114.7 & 22.9952 & 26.8508 & 29.97739386912141 \\
			\bottomrule
		\end{tabular}
	}
	\caption{Results when using Fitness Proportional Selection as parent selection method.}
	\label{tab:selparentfitprop}
\end{table}

\subsection{7b: Survivor selection}
Round robin tournament was chosen as the other strategy for survivor selection. The results for different percentages of elitism for survival selection can be found in appendix~\ref{app:task2} in table~\ref{tab:vary_elitism}. To evaluate how round robin tournament performs compared to the already implemented elitism, the elitism percentage is set to 0\% in an experiment. Also, an experiment is done where round robin tournament is combined with an elitism percentage of 30\%. Table~\ref{tab:survivor_selection} contains the results of the experiments for this task. The size of the tournaments was set to 10, as recommended by the textbook.

The round robin tournament strategy outperforms every percentage of elitism. Combining round robin tournament with elitism results in longer path lengths overall. This happens because the elitism causes the round robin tournament to be executed on a smaller population; the two methods compete with each other. Therefore, it is better to set elitism to zero when using round robin tournament.
\input{task7b}

\subsection{7c: Diversity preservation}
In order to preserve population diversity, we adapted a few of the functions in the template to work with subpopulations, simulating the island model. In addition to the number of supopulations, the number of individuals was also increased from 100 to 800 in these experiments. This way there is a reasonable amount of individuals in each subpopulation for each experiment. 

The results displayed in appendix~\ref{app:task7c} table~\ref{tab:diversity} show tests performed with 1, 2, 5, 10 and 20 subpopulations or islands. The results show a clear downwards trend in terms of path length when increasing the number of subpopulations. When the number of subpopulations is high, the number of individuals decreases enough to negatively impact path length. When the number of subpopulations is lower (e.g. 2 or 5) the performance is comparable to results of experiments performed for task 2 with the corresponding number of individuals in a single subpopulation.

We did not implement any communication mechanisms between subpopulations. We suspect that the addition of migration might improve the results we observed.

\section{Task 6: Benchmark problems}
For this task, we have selected a set of parameters and methods based on all of the results above. Our algorithm is evaluated by running it on the given benchmark problems and calculating the relative error of the results of the algorithm to the known optimal paths of the benchmark problems. 

The parameters used were: \texttt{number of individuals} = 1000, \texttt{maximum number of generations} = 1000, \texttt{probability of mutation} = 0.5, \texttt{probability of crossover} = 0.35, \texttt{percentage of elite population} = 0, \texttt{subpopulations} = 1, \texttt{loop detection} = 1, \texttt{selection function} = sel\_tournament, \texttt{crossover function} = cross\_order, \texttt{mutation function} = mut\_inversion, \texttt{custom stopping criterion} = off, \texttt{custom survivor selection function} = on (round robin tournament).

The results are shown in table~\ref{tab:benchmark}. Table\ref{tab:benchmark_defaults} contains results for the benchmark problems when using the default parameters mentioned in the introduction, but with \texttt{number of individuals} = 1000 and \texttt{maximum number of generations} = 1000. Judging from the relative errors, we can conclude that our final algorithm performs much better. The algorithm achieves lower relative errors on datasets with lower amounta of cities (xqf131 and bcl380). The relative errors for datasets with higher amounts of cities lie a bit higher.
\input{task6_benchmark}
\input{task6_benchmark_defaults}

\newpage
\section{Conclusion}

For this project, we ran and evaluated many experiments. In task 2, we looked at the effects of parameter tuning on the `bare' genetic algorithm. We mainly noticed that by themselves, the parameters all have a relatively small impact. However, tuning the parameters together can give much better results on the datasets.

The new stopping criterion developed for task 3 allows us to gain on computation time while sacrificing a bit in minimal path length. Task 4 showed us that Order Crossover on chromosomes in path representation outperforms Alternating Edge Crossover for every dataset, and that Inversion Mutation is not really better than its Simple version in this case. Also, local loop removal is a must according to the experiments we performed for task 5. It decreases both path length and number of generations required.

For the optional tasks, we decided to implement Fitness Proportional Selection and Tournament Selection for task 7a, where we saw that only tournament selection had an impact on performance. Furthermore, we implemented RR Tournament survivor selection for task 7b. It had a positive effect when used by itself, but this effect decreased when used with the already implemented elitism. Lastly, we experimented with multiple subpopulations for task 7c in an attempt to avoid premature convergence, but it ended up not being helpful in the context of this project.

We put the knowledge gained from doing all these tasks to the test when tuning the final parameters for the benchmark tests, and achieved ... TODO resultaten.

\mychapter{4}{Appendix}
\section{Tables}
\subsection{Task 2}
\label{app:task2}
\input{task2_individuals}
\input{task2_generations}
\input{task2_elitism}
\input{task2_crossover}
\input{task2_mutation}

\subsection{Task 7c}
\label{app:task7c}
\begin{table}[H]
	\centering
	\makebox[\textwidth]{
		\begin{tabular}{l rrrr}
			\toprule
			Dataset & \# Generations & Min & Mean & Max \\
			\midrule
			\multicolumn{5}{c}{\# subpopulations = 1}\\ 
			\midrule
			rondrit016.tsp & 87.3 & 3.3789 & 4.8268 & 6.8628 \\
			rondrit048.tsp & 158.8 & 8.7074 & 14.5176 & 19.8265 \\
			rondrit067.tsp & 102.1 & 13.5305 & 18.8152 & 23.4651 \\
			rondrit127.tsp & 139.6 & 20.8300 & 26.1699 & 30.2266 \\
			\midrule
			\multicolumn{5}{c}{\# subpopulations = 2}\\ 
			\midrule
			rondrit016.tsp & 86.5 & 3.7069 & 5.3631 & 7.6527 \\
			rondrit048.tsp & 109.0 & 10.6332 & 16.4698 & 22.6468 \\
			rondrit067.tsp & 145.5 & 14.3458 & 20.4498 & 25.6300 \\
			rondrit127.tsp & 153.6 & 22.8718 & 28.8169 & 33.7587 \\
			\midrule
			\multicolumn{5}{c}{\# subpopulations = 5}\\ 
			\midrule
			rondrit016.tsp & 96.7 & 3.7377 & 5.3840 & 7.5751 \\
			rondrit048.tsp & 150.1 & 10.2174 & 16.3796 & 22.4803 \\
			rondrit067.tsp & 113.1 & 14.9047 & 20.8687 & 26.0722 \\
			rondrit127.tsp & 176.2 & 22.6508 & 28.8988 & 33.6638 \\
			\midrule
			\multicolumn{5}{c}{\# subpopulations = 10}\\ 
			\midrule
			rondrit016.tsp & 101.6 & 3.7363 & 5.4124 & 7.7952 \\
			rondrit048.tsp & 162.2 & 9.8346 & 16.3824 & 22.4776 \\
			rondrit067.tsp & 183.9 & 13.6331 & 20.3402 & 25.7013 \\
			rondrit127.tsp & 189.3 & 22.6947 & 28.9111 & 33.7984 \\
			\midrule
			\multicolumn{5}{c}{\# subpopulations = 20}\\ 
			\midrule
			rondrit016.tsp & 97.1 & 3.7418 & 5.4420 & 7.7813 \\
			rondrit048.tsp & 128.2 & 10.4201 & 16.5968 & 22.4393 \\
			rondrit067.tsp & 135.2 & 14.8073 & 20.9061 & 26.2982 \\
			rondrit127.tsp & 136.0 & 23.5869 & 29.2883 & 34.0429 \\
			\bottomrule
		\end{tabular}
	}
	\caption{Comparison of results when using 1, 2, 5, 10 and 20 subpopulations.}
	\label{tab:diversity}
\end{table}

\section{Code}
\lstinputlisting[language=matlab,captionpos=t,caption=The main algorithm - src/run\_ga.m]{../src/run_ga.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Order crossover for task 4-  src/cross\_order.m]{../src/cross_order.m}
\lstinputlisting[language=matlab,captionpos=t,caption=High level crossover function-  src/crossover\_tsp.m]{../src/crossover_tsp.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Inversion mutation for task 4 - src/mut\_inversion2.m]{../src/mut_inversion2.m}
\lstinputlisting[language=matlab,captionpos=t,caption=High level mutation function - src/mutate\_tsp.m]{../src/mutate_tsp.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Fitness proportional selection for task 7a - src/sel\_fit\_prop.m]{../src/sel_fit_prop.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Tournament selection for task 7a - src/sel\_tournament.m]{../src/sel_tournament.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Round robin tournament survival selection for task 7b - src/sur\_sel\_rr\_tournament.m]{../src/sur_sel_rr_tournament.m}
\lstinputlisting[language=matlab,captionpos=t,caption=Template function for testing the algorithm. Other testing functions are omitted because they are very similar to this one - src/test\_template.m]{../src/test_template.m} 

\end{document}
